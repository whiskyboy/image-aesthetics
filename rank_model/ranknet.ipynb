{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           1048832     input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 256)           1024        dense_1[0][0]                    \n",
      "                                                                   dense_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 256)           0           batch_normalization_1[0][0]      \n",
      "                                                                   batch_normalization_1[1][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             257         dropout_1[0][0]                  \n",
      "                                                                   dropout_1[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 1)             0           dense_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 1)             0           dense_2[0][0]                    \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1)             0           add_1[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 1,050,113\n",
      "Trainable params: 1,049,601\n",
      "Non-trainable params: 512\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Add, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "img_feature_a = Input(shape=(1024*4,))\n",
    "img_feature_b = Input(shape=(1024*4,))\n",
    "\n",
    "h_1 = Dense(256, activation='relu')\n",
    "bn_1 = BatchNormalization()\n",
    "do_1 = Dropout(0.5)\n",
    "#h_2 = Dense(64, activation='relu')\n",
    "#bn_2 = BatchNormalization()\n",
    "#do_2 = Dropout(0.5)\n",
    "s = Dense(1)\n",
    "\n",
    "def aesthetic_layer(x):\n",
    "    x = h_1(x)\n",
    "    x = bn_1(x)\n",
    "    x = do_1(x)\n",
    "    #x = h_2(x)\n",
    "    #x = bn_2(x)\n",
    "    #x = do_2(x)\n",
    "    return s(x)\n",
    "\n",
    "score_a = aesthetic_layer(img_feature_a)\n",
    "score_b = aesthetic_layer(img_feature_b)\n",
    "\n",
    "negated_score_b = Lambda(lambda x: -x, output_shape=(1,))(score_b)\n",
    "diff = Add()([score_a, negated_score_b])\n",
    "\n",
    "output = Activation(\"sigmoid\")(diff)\n",
    "\n",
    "ranknet = Model(inputs=[img_feature_a, img_feature_b], outputs=output)\n",
    "\n",
    "#optimizer = optimizers.RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ranknet.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ranknet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 375764 images belonging to 1 classes.\n",
      "Found 4277 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# define the data\n",
    "from keras.preprocessing.image import *\n",
    "import os\n",
    "import numpy as np\n",
    "import lmdb\n",
    "import random\n",
    "\n",
    "env = lmdb.open(\"./data/mobilenet_feature/\")\n",
    "txn = env.begin()\n",
    "\n",
    "def get_feature(imgid):\n",
    "    str_feature = txn.get(imgid)\n",
    "    return np.fromstring(str_feature, np.float32)\n",
    "\n",
    "# 自定义DirectoryIterator类，可以返回自定义的label\n",
    "class CustomDirectoryIterator(DirectoryIterator):  \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        batch_x1 = np.zeros((current_batch_size,) + self.target_size, dtype=K.floatx())\n",
    "        batch_x2 = np.zeros((current_batch_size,) + self.target_size, dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size, ) , dtype=K.floatx())\n",
    "        # build batch of image data\n",
    "        for i, j in enumerate(index_array):\n",
    "            fname =  self.filenames[j]\n",
    "            fname = os.path.basename(fname)\n",
    "            fname, _ = os.path.splitext(fname)\n",
    "            imgA, imgB, cmpret = fname.split(\"_\")\n",
    "            x1 = get_feature(imgA)\n",
    "            x2 = get_feature(imgB)\n",
    "            batch_x1[i] = x1\n",
    "            batch_x2[i] = x2\n",
    "            batch_y[i] = int(cmpret)\n",
    "        return [batch_x1, batch_x2], batch_y\n",
    "\n",
    "# 定义批处理的数据集大小：较小的batch_size可以增加权重调整的次数，同时节省内存的开销\n",
    "batch_size = 64 \n",
    "\n",
    "# 图片预处理工具类\n",
    "train_IDG = ImageDataGenerator(vertical_flip=True, zoom_range=0.1)\n",
    "valid_IDG = ImageDataGenerator()\n",
    "\n",
    "# 从目录文件中流式读取数据，避免训练中一次性加载爆内存\n",
    "train_batch = CustomDirectoryIterator(\"./data/train/\", train_IDG, \n",
    "                                      target_size=(1024*4, ), batch_size=batch_size, shuffle=True)\n",
    "valid_batch = CustomDirectoryIterator(\"./data/valid/\", valid_IDG, \n",
    "                                      target_size=(1024*4, ), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5871/5871 [==============================] - 13s - loss: 0.5326 - acc: 0.7458 - val_loss: 0.6808 - val_acc: 0.5953\n",
      "Epoch 2/3\n",
      "5871/5871 [==============================] - 13s - loss: 0.5280 - acc: 0.7452 - val_loss: 0.6804 - val_acc: 0.6000\n",
      "Epoch 3/3\n",
      "5871/5871 [==============================] - 13s - loss: 0.5245 - acc: 0.7444 - val_loss: 0.6799 - val_acc: 0.6024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b3a458e50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranknet.fit_generator(train_batch, steps_per_epoch=train_batch.samples // batch_size, epochs=3,\n",
    "                       validation_data=valid_batch, validation_steps=valid_batch.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"./data/ranknet/ranknet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
