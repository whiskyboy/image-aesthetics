{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, concatenate, Activation, Add, Lambda, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 3, 256, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 1)             6064929     input_3[0][0]                    \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 3, 256, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 1)             0           sequential_2[2][0]               \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 1)             0           sequential_2[1][0]               \n",
      "                                                                   lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 1)             0           add_2[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 6,064,929\n",
      "Trainable params: 6,064,929\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_a = Input(shape=(3, 256, 256))\n",
    "img_b = Input(shape=(3, 256, 256))\n",
    "\n",
    "score_model = Sequential()\n",
    "\n",
    "score_model.add(Conv2D(filters=32, kernel_size=(11, 11), activation=\"relu\", input_shape=(3, 256, 256)))\n",
    "score_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "score_model.add(Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\"))\n",
    "score_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "#model.add(BatchNormalization())\n",
    "score_model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "score_model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "score_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "#score_model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "#score_model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "score_model.add(Flatten())\n",
    "score_model.add(Dense(128, activation='relu'))\n",
    "#score_model.add(BatchNormalization())\n",
    "#score_model.add(Dropout(0.5))\n",
    "score_model.add(Dense(1))\n",
    "\n",
    "score_a = score_model(img_a)\n",
    "score_b = score_model(img_b)\n",
    "\n",
    "negated_score_b = Lambda(lambda x: -x, output_shape=(1,))(score_b)\n",
    "diff = Add()([score_a, negated_score_b])\n",
    "\n",
    "output = Activation(\"sigmoid\")(diff)\n",
    "\n",
    "ranknet = Model(inputs=[img_a, img_b], outputs=output)\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ranknet.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "ranknet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = \"../data/img/\"\n",
    "def img_preprocess(imgid, target_size=(299, 299)):\n",
    "    try:\n",
    "        filename = img_path+\"%s.jpg\"%imgid\n",
    "        img = image.load_img(filename, target_size=target_size)\n",
    "        x = image.img_to_array(img)\n",
    "        return x\n",
    "    except Exception, e:\n",
    "        print str(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ONCE\n",
    "import cPickle as pickle\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "train_list = pickle.load(open(\"./data/ranknet/train.list\", 'rb'))\n",
    "valid_list = pickle.load(open(\"./data/ranknet/valid.list\", 'rb'))\n",
    "\n",
    "if os.path.exists(\"./data/ranknet_from_scratch\"):\n",
    "    shutil.rmtree(\"./data/ranknet_from_scratch\")\n",
    "os.makedirs(\"./data/ranknet_from_scratch/train/none\")\n",
    "os.makedirs(\"./data/ranknet_from_scratch/valid/none\")\n",
    "\n",
    "white_set = set()\n",
    "def touch_files(dataset, path, count=-1):\n",
    "    if count != -1:\n",
    "        subdata = random.sample(dataset, count)\n",
    "    else:\n",
    "        subdata = dataset\n",
    "    for imgA, sA, imgB, sB, cmpret in subdata:\n",
    "        if imgA in white_set or img_preprocess(imgA) is not None:\n",
    "            white_set.add(imgA)\n",
    "        if imgB in white_set or img_preprocess(imgB) is not None:\n",
    "            white_set.add(imgB)\n",
    "        if imgA in white_set and imgB in white_set:\n",
    "            open(path+\"/%s_%s_%d.jpg\"%(imgA, imgB, cmpret), 'w').close()\n",
    "        \n",
    "touch_files(train_list, path=\"./data/ranknet_from_scratch/train/none/\", count=100000)\n",
    "touch_files(valid_list, path=\"./data/ranknet_from_scratch/valid/none/\", count=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99530 images belonging to 1 classes.\n",
      "Found 4334 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import *\n",
    "import os\n",
    "\n",
    "# 自定义DirectoryIterator类，可以返回自定义的label\n",
    "class CustomDirectoryIterator(DirectoryIterator):  \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        batch_x1 = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n",
    "        batch_x2 = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size, ) , dtype=K.floatx())\n",
    "        # build batch of image data\n",
    "        for i, j in enumerate(index_array):\n",
    "            fname =  self.filenames[j]\n",
    "            fname = os.path.basename(fname)\n",
    "            fname, _ = os.path.splitext(fname)\n",
    "            imgA, imgB, cmpret = fname.split(\"_\")\n",
    "            x1 = img_preprocess(imgA, self.target_size)\n",
    "            x2 = img_preprocess(imgB, self.target_size)\n",
    "            batch_x1[i] = x1\n",
    "            batch_x2[i] = x2\n",
    "            batch_y[i] = int(cmpret)\n",
    "        return [batch_x1, batch_x2], batch_y\n",
    "\n",
    "# 定义批处理的数据集大小：较小的batch_size可以增加权重调整的次数，同时节省内存的开销\n",
    "batch_size = 16 \n",
    "\n",
    "# 图片预处理工具类\n",
    "IDG = ImageDataGenerator()\n",
    "\n",
    "# 从目录文件中流式读取数据，避免训练中一次性加载爆内存\n",
    "train_batch = CustomDirectoryIterator(\"./data/ranknet_from_scratch/train/\", IDG, \n",
    "                                      target_size=(256, 256), batch_size=batch_size, shuffle=True)\n",
    "valid_batch = CustomDirectoryIterator(\"./data/ranknet_from_scratch/valid/\", IDG, \n",
    "                                      target_size=(256, 256), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6220/6220 [==============================] - 1636s - loss: 0.7060 - acc: 0.5691 - val_loss: 0.7294 - val_acc: 0.5206\n",
      "Epoch 2/10\n",
      "6220/6220 [==============================] - 1626s - loss: 0.4988 - acc: 0.7537 - val_loss: 0.9570 - val_acc: 0.5345\n",
      "Epoch 3/10\n",
      "6220/6220 [==============================] - 1625s - loss: 0.2627 - acc: 0.8945 - val_loss: 1.1643 - val_acc: 0.5310\n",
      "Epoch 4/10\n",
      "6220/6220 [==============================] - 1626s - loss: 0.1590 - acc: 0.9425 - val_loss: 1.2906 - val_acc: 0.5285\n",
      "Epoch 5/10\n",
      "6220/6220 [==============================] - 1632s - loss: 0.1146 - acc: 0.9605 - val_loss: 1.3951 - val_acc: 0.5312\n",
      "Epoch 6/10\n",
      "6220/6220 [==============================] - 1671s - loss: 0.0833 - acc: 0.9725 - val_loss: 1.4036 - val_acc: 0.5271\n",
      "Epoch 7/10\n",
      "6220/6220 [==============================] - 1716s - loss: 0.0670 - acc: 0.9787 - val_loss: 1.7835 - val_acc: 0.5345\n",
      "Epoch 8/10\n",
      "6220/6220 [==============================] - 1646s - loss: 0.0548 - acc: 0.9826 - val_loss: 1.6610 - val_acc: 0.5308\n",
      "Epoch 9/10\n",
      "6220/6220 [==============================] - 1628s - loss: 0.0473 - acc: 0.9857 - val_loss: 1.6964 - val_acc: 0.5331\n",
      "Epoch 10/10\n",
      "6220/6220 [==============================] - 1626s - loss: 0.0410 - acc: 0.9877 - val_loss: 1.8884 - val_acc: 0.5377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5415747410>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranknet.fit_generator(train_batch, steps_per_epoch=train_batch.samples // batch_size, epochs=10,\n",
    "                       validation_data=valid_batch, validation_steps=valid_batch.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranknet.save_weights(\"./data/ranknet_from_scratch/ranknet_from_scratch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
