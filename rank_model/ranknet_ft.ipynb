{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation, Add, Concatenate, Lambda, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 214, 214, 32)  11648       input_2[0][0]                    \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 107, 107, 32)  0           conv2d_1[0][0]                   \n",
      "                                                                   conv2d_1[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 103, 103, 32)  25632       max_pooling2d_1[0][0]            \n",
      "                                                                   max_pooling2d_1[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 51, 51, 32)    0           conv2d_2[0][0]                   \n",
      "                                                                   conv2d_2[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 49, 49, 64)    18496       max_pooling2d_2[0][0]            \n",
      "                                                                   max_pooling2d_2[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 49, 49, 64)    0           conv2d_3[0][0]                   \n",
      "                                                                   conv2d_3[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 47, 47, 64)    36928       dropout_1[0][0]                  \n",
      "                                                                   dropout_1[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 47, 47, 64)    0           conv2d_4[0][0]                   \n",
      "                                                                   conv2d_4[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 23, 23, 64)    0           dropout_2[0][0]                  \n",
      "                                                                   dropout_2[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 33856)         0           max_pooling2d_3[0][0]            \n",
      "                                                                   max_pooling2d_3[1][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 224, 224, 3)   0           input_2[0][0]                    \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          34669568    flatten_1[0][0]                  \n",
      "                                                                   flatten_1[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "mobilenet_1.00_224 (Model)       (None, 1024)          3228864     lambda_1[0][0]                   \n",
      "                                                                   lambda_1[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           262400      dense_1[0][0]                    \n",
      "                                                                   dense_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 256)           262400      mobilenet_1.00_224[1][0]         \n",
      "                                                                   mobilenet_1.00_224[2][0]         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 256)           1024        dense_2[0][0]                    \n",
      "                                                                   dense_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 256)           1024        dense_3[0][0]                    \n",
      "                                                                   dense_3[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 256)           0           batch_normalization_1[0][0]      \n",
      "                                                                   batch_normalization_1[1][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 256)           0           batch_normalization_2[0][0]      \n",
      "                                                                   batch_normalization_2[1][0]      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 512)           0           dropout_3[0][0]                  \n",
      "                                                                   dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 512)           0           dropout_3[1][0]                  \n",
      "                                                                   dropout_4[1][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             513         concatenate_1[0][0]              \n",
      "                                                                   concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 1)             0           dense_4[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 1)             0           dense_4[0][0]                    \n",
      "                                                                   lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 1)             0           add_1[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 38,518,497\n",
      "Trainable params: 35,288,609\n",
      "Non-trainable params: 3,229,888\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_1 = Conv2D(filters=32, kernel_size=(11, 11), activation=\"relu\")\n",
    "pool_1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "conv_2 = Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\")\n",
    "pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "conv_3 = Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\")\n",
    "cnn_do_1 = Dropout(0.8)\n",
    "conv_4 = Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\")\n",
    "cnn_do_2 = Dropout(0.8)\n",
    "pool_3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
    "flatten = Flatten()\n",
    "dense = Dense(1024, activation='relu')\n",
    "\n",
    "def CNNnet(x):\n",
    "    x = conv_1(x)\n",
    "    x = pool_1(x)\n",
    "    x = conv_2(x)\n",
    "    x = pool_2(x)\n",
    "    x = conv_3(x)\n",
    "    x = cnn_do_1(x)\n",
    "    x = conv_4(x)\n",
    "    x = cnn_do_2(x)\n",
    "    x = pool_3(x)\n",
    "    x = flatten(x)\n",
    "    x = dense(x)\n",
    "    return x\n",
    "\n",
    "preprocess_layer = Lambda(lambda x: preprocess_input(x), output_shape=(224,224,3))\n",
    "mobilenet = MobileNet(input_shape=(224, 224, 3), weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "h_1_1 = Dense(256, activation='relu')\n",
    "h_1_2 = Dense(256, activation='relu')\n",
    "bn_1_1 = BatchNormalization()\n",
    "bn_1_2 = BatchNormalization()\n",
    "do_1_1 = Dropout(0.5)\n",
    "do_1_2 = Dropout(0.5)\n",
    "s = Dense(1)\n",
    "def aesthetic_net(img):\n",
    "    cnn_output = CNNnet(img)\n",
    "    mobilenet_output = mobilenet(preprocess_layer(img))\n",
    "    \n",
    "    x1 = h_1_1(cnn_output)\n",
    "    x1 = bn_1_1(x1)\n",
    "    x1 = do_1_1(x1)\n",
    "    \n",
    "    x2 = h_1_2(mobilenet_output)\n",
    "    x2 = bn_1_2(x2)\n",
    "    x2 = do_1_2(x2)\n",
    "    \n",
    "    merge_feature = Concatenate()([x1, x2])\n",
    "    \n",
    "    return s(merge_feature)\n",
    "    \n",
    "\n",
    "img_a = Input(shape=(224, 224, 3))\n",
    "img_b = Input(shape=(224, 224, 3))\n",
    "\n",
    "s_a = aesthetic_net(img_a)\n",
    "s_b = aesthetic_net(img_b)\n",
    "\n",
    "ns_b = Lambda(lambda x: -x, output_shape=(1,))(s_b)\n",
    "diff = Add()([s_a, ns_b])\n",
    "\n",
    "output = Activation(\"sigmoid\")(diff)\n",
    "\n",
    "ranknet = Model(inputs=[img_a, img_b], outputs=output)\n",
    "\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#optimizer = optimizers.RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "ranknet.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ranknet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 375764 images belonging to 1 classes.\n",
      "Found 4277 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# define the data\n",
    "from keras.preprocessing.image import *\n",
    "import os\n",
    "\n",
    "img_path = \"../data/img/\"\n",
    "def load_img_array(imgid, target_size):\n",
    "    filename = img_path+\"%s.jpg\"%imgid\n",
    "    img = image.load_img(filename, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    return x\n",
    "\n",
    "# 自定义DirectoryIterator类，可以返回自定义的label\n",
    "class CustomDirectoryIterator(DirectoryIterator):  \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        batch_x1 = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n",
    "        batch_x2 = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size, ) , dtype=K.floatx())\n",
    "        # build batch of image data\n",
    "        for i, j in enumerate(index_array):\n",
    "            fname =  self.filenames[j]\n",
    "            fname = os.path.basename(fname)\n",
    "            fname, _ = os.path.splitext(fname)\n",
    "            imgA, imgB, cmpret = fname.split(\"_\")\n",
    "            x1 = load_img_array(imgA, self.target_size)\n",
    "            x2 = load_img_array(imgB, self.target_size)\n",
    "            batch_x1[i] = x1\n",
    "            batch_x2[i] = x2\n",
    "            batch_y[i] = int(cmpret)\n",
    "        return [batch_x1, batch_x2], batch_y\n",
    "\n",
    "# 定义批处理的数据集大小：较小的batch_size可以增加权重调整的次数，同时节省内存的开销\n",
    "batch_size = 32 \n",
    "\n",
    "# 图片预处理工具类\n",
    "train_IDG = ImageDataGenerator(vertical_flip=True, zoom_range=0.1)\n",
    "valid_IDG = ImageDataGenerator()\n",
    "\n",
    "# 从目录文件中流式读取数据，避免训练中一次性加载爆内存\n",
    "train_batch = CustomDirectoryIterator(\"./data/train/\", train_IDG, \n",
    "                                      target_size=(224, 224), batch_size=batch_size, shuffle=True)\n",
    "valid_batch = CustomDirectoryIterator(\"./data/valid/\", valid_IDG, \n",
    "                                      target_size=(224, 224), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 5712s - loss: 0.6062 - acc: 0.6733 - val_loss: 0.6671 - val_acc: 0.6170\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 5728s - loss: 0.5894 - acc: 0.6877 - val_loss: 0.6804 - val_acc: 0.6113\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 5780s - loss: 0.5825 - acc: 0.6934 - val_loss: 0.6589 - val_acc: 0.6113\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 5769s - loss: 0.5704 - acc: 0.7042 - val_loss: 0.6642 - val_acc: 0.6247\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 5774s - loss: 0.5628 - acc: 0.7108 - val_loss: 0.6866 - val_acc: 0.6097\n",
      "Epoch 1/1\n",
      "11742/11742 [==============================] - 5772s - loss: 0.4208 - acc: 0.8054 - val_loss: 0.7796 - val_acc: 0.5974\n",
      "Epoch 1/1\n",
      " 7647/11742 [==================>...........] - ETA: 1989s - loss: 0.2535 - acc: 0.8956"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4f2ce7a415f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     ranknet.fit_generator(train_batch, steps_per_epoch=train_batch.samples // batch_size, epochs=1,\n\u001b[0;32m----> 3\u001b[0;31m                        validation_data=valid_batch, validation_steps=valid_batch.samples // batch_size)\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mranknet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./model/ranknet_ft_epoch%02d.h5\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0m_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tian/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _epoch in range(10):\n",
    "    ranknet.fit_generator(train_batch, steps_per_epoch=train_batch.samples // batch_size, epochs=1,\n",
    "                       validation_data=valid_batch, validation_steps=valid_batch.samples // batch_size)\n",
    "    ranknet.save_weights(\"./model/ranknet_ft_epoch%02d.h5\"%_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranknet.save_weights(\"./data/ranknet_ft/ranknet_ft.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
