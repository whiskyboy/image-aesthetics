{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use InceptionV3 for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义InvecptionV3的预处理模型\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) # add a global spatial average pooling layer\n",
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对每张照片预处理并存储在lmdb里\n",
    "import lmdb\n",
    "\n",
    "batch_size = 128\n",
    "img_path = \"../data/img/\"\n",
    "\n",
    "imgid_set = set(map(lambda x: x[0], train_list) + \\\n",
    "            map(lambda x: x[2], train_list) + \\\n",
    "            map(lambda x: x[0], valid_list) + \\\n",
    "            map(lambda x: x[2], valid_list))\n",
    "env = lmdb.open(\"./data/features\", map_size=8192*3*len(imgid_set))\n",
    "\n",
    "def preprocess(imgid):\n",
    "    try:\n",
    "        filename = img_path+\"%s.jpg\"%imgid\n",
    "        img = image.load_img(filename, target_size=(299, 299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "        return x\n",
    "    except Exception, e:\n",
    "        print str(e)\n",
    "        return None\n",
    "\n",
    "imgids = []\n",
    "X = []\n",
    "for i, imgid in enumerate(imgid_set):\n",
    "    x = preprocess(imgid)\n",
    "    if x is None:\n",
    "        continue\n",
    "    imgids.append(imgid)\n",
    "    X.append(x)\n",
    "    if len(X) == batch_size:\n",
    "        features = model.predict_on_batch(np.array(X))\n",
    "        \n",
    "        txn = env.begin(write=True)\n",
    "        for _imgid, _feature in zip(imgids, features):\n",
    "            str_feature = _feature.tostring()\n",
    "            txn.put(_imgid, str_feature)\n",
    "        txn.commit()\n",
    "        \n",
    "        imgids = []\n",
    "        X = []\n",
    "        print \"%d/%d\"%(i, len(imgid_set))\n",
    "        \n",
    "if len(X) > 0:\n",
    "    features = model.predict_on_batch(np.array(X))\n",
    "    txn = env.begin(write=True)\n",
    "    for _imgid, _feature in zip(imgids, features):\n",
    "        str_feature = _feature.tostring()\n",
    "        txn.put(_imgid, str_feature)\n",
    "    txn.commit()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use mobilenet for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "base_model = MobileNet(input_shape=(224, 224, 3), weights='imagenet', include_top=False, pooling='avg')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import os\n",
    "import cPickle as pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 128\n",
    "img_path = \"../data/img/\"\n",
    "\n",
    "env = lmdb.open(\"./data/mobilenet_feature\", map_size=8192*3*100000)\n",
    "ALL_IMGIDS = set()\n",
    "\n",
    "def img_preprocess(imgfile):\n",
    "    try:\n",
    "        filename = img_path+imgfile\n",
    "        img = image.load_img(filename, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "        return x\n",
    "    except Exception, e:\n",
    "        return None\n",
    "    \n",
    "def save_to_lmdb(imgids, features):\n",
    "    txn = env.begin(write=True)\n",
    "    for _imgid, _feature in zip(imgids, features):\n",
    "        str_feature = _feature.tostring()\n",
    "        txn.put(_imgid, str_feature)\n",
    "    txn.commit()\n",
    "\n",
    "batch_imgids = []\n",
    "batch_X = []\n",
    "for imgfile in tqdm(os.listdir(img_path)):\n",
    "    x = img_preprocess(imgfile)\n",
    "    if x is None:\n",
    "        continue\n",
    "    batch_X.append(x)\n",
    "    batch_imgids.append(os.path.splitext(imgfile)[0])\n",
    "    ALL_IMGIDS.add(os.path.splitext(imgfile)[0])\n",
    "    if len(batch_X) == batch_size:\n",
    "        batch_features = base_model.predict_on_batch(np.array(batch_X))\n",
    "        save_to_lmdb(batch_imgids, batch_features)\n",
    "        batch_imgids = []\n",
    "        batch_X = []\n",
    "        \n",
    "if len(batch_X) > 0:\n",
    "    batch_features = base_model.predict_on_batch(np.array(batch_X))\n",
    "    save_to_lmdb(batch_imgids, batch_features)\n",
    "\n",
    "env.close()\n",
    "\n",
    "pickle.dump(ALL_IMGIDS, open(\"./data/ALL_IMGIDS.pick\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use Fisher-Vector for generic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fisher import *\n",
    "\n",
    "# train GMM\n",
    "gmm = Gmm(K=256)\n",
    "gmm.generate(\"../data/img/\", img_size=(256, 256), limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train FishVectors\n",
    "limit = 1000\n",
    "fisher_vector = FisherVector(gmm)\n",
    "\n",
    "files = glob.glob(folder + \"/*.jpg\")[:limit]\n",
    "for imgfile in files:\n",
    "    v = fisher_vector.fisher_vector_of_file(imgfile)\n",
    "    if v is not None:\n",
    "\n",
    "        with ProcessPoolExecutor() as pool:\n",
    "            futures = pool.map(self._worker, files)\n",
    "            desc = 'Creating Fisher Vectors {} images of folder {}'.format(len(files), os.path.split(folder)[-1])\n",
    "            futures = tqdm.tqdm(futures, total=len(files), desc=desc, unit='image', ncols=120)\n",
    "            vectors = [f for f in futures if f is not None and len(f) > 0]\n",
    "            max_shape = np.array([v.shape[0] for v in vectors]).max()\n",
    "            vectors = [v for v in vectors if v.shape[0] == max_shape]\n",
    "        # return np.array(vectors)    # Can't do np.float32, because all images may not have same number of features\n",
    "        return np.float32(vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算并存储每张图片的score\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "\n",
    "ALL_IMGIDS = pickle.load(open(\"./data/ALL_IMGIDS.pick\", 'rb'))\n",
    "\n",
    "def get_score(zan_num, cai_num, clk_num):\n",
    "    zan_num = max(zan_num - 1, 0)\n",
    "    return zan_num - cai_num + np.round(np.log(clk_num+1))\n",
    "\n",
    "img_score_by_date = {}\n",
    "with open(\"../data/img_attr.csv\", 'r') as fin:\n",
    "    for line in fin:\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        if len(fields) != 7:\n",
    "            continue\n",
    "        imgid = fields[0]\n",
    "        zan_num = int(fields[1])\n",
    "        cai_num = int(fields[2])\n",
    "        clk_num = int(fields[3])\n",
    "        score = get_score(zan_num, cai_num, clk_num)\n",
    "        date = fields[5]\n",
    "        if imgid in ALL_IMGIDS and date >= \"2015/01\" and date < \"2017/01\":\n",
    "            img_score_by_date.setdefault(date, [])\n",
    "            img_score_by_date[date].append((imgid, score))\n",
    "\n",
    "print \"#count of images: %d\"%sum(map(len, img_score_by_date.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造用于模型训练和验证的pair数据对\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(\"./data/train\"):\n",
    "    shutil.rmtree(\"./data/train\")\n",
    "if os.path.exists(\"./data/valid\"):\n",
    "    shutil.rmtree(\"./data/valid\")\n",
    "os.makedirs(\"./data/train/none\")\n",
    "os.makedirs(\"./data/valid/none\")\n",
    "\n",
    "def split_dataset(dataset, p):\n",
    "    \"\"\"\n",
    "    return train_dataset, valid_dataset\n",
    "    \"\"\"\n",
    "    random.shuffle(dataset)\n",
    "    valid_size = int(len(dataset)*p)\n",
    "    return dataset[:-valid_size], dataset[-valid_size:]\n",
    "\n",
    "train_list = []\n",
    "valid_list = []\n",
    "p = 0.1 # valid_data ratio\n",
    "k = 20 # compare with k images for each train image\n",
    "delta = 1.5 # if abs(sa-sb) < delta, then abort this comparation pair\n",
    "for date, imgs in img_score_by_date.items():\n",
    "    train_imgs, valid_imgs = split_dataset(imgs, p)\n",
    "    cmp_k = len(train_imgs) > k and k or len(train_imgs)\n",
    "    \n",
    "    for img_a, s_a in train_imgs:\n",
    "        for img_b, s_b in random.sample(train_imgs, cmp_k):\n",
    "            if abs(s_a-s_b) < delta:\n",
    "                continue\n",
    "            cmp_ret = s_a > s_b and 1 or 0\n",
    "            train_list.append((img_a, s_a, img_b, s_b, cmp_ret))\n",
    "            open(\"./data/train/none/%s_%s_%d.jpg\"%(img_a, img_b, cmp_ret), 'w').close()\n",
    "            \n",
    "    for img_a, s_a in valid_imgs:\n",
    "        img_b, s_b = random.choice(valid_imgs)\n",
    "        if abs(s_a-s_b) < 0.5:\n",
    "            continue\n",
    "        cmp_ret = s_a > s_b and 1 or 0\n",
    "        valid_list.append((img_a, s_a, img_b, s_b, cmp_ret))\n",
    "        open(\"./data/valid/none/%s_%s_%d.jpg\"%(img_a, img_b, cmp_ret), 'w').close()\n",
    "            \n",
    "print \"Length of Train List: %d\"%len(train_list)\n",
    "print \"Length of Valid List: %d\"%len(valid_list)\n",
    "\n",
    "pickle.dump(train_list, open(\"./data/train_list.pick\", 'wb'))\n",
    "pickle.dump(valid_list, open(\"./data/valid_list.pick\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
