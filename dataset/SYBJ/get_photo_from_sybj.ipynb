{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    datefmt='%m-%d %H:%M')\n",
    "\n",
    "request_root_url = \"http://www.sybj.com\"\n",
    "request_headers = {'User-Agent' : 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'}\n",
    "sleep_second = 3\n",
    "\n",
    "def get_html(page_url):\n",
    "    url = request_root_url + page_url\n",
    "    request = urllib2.Request(url, headers=request_headers)\n",
    "    response = urllib2.urlopen(request, timeout=60)\n",
    "    html = response.read()\n",
    "    return html\n",
    "\n",
    "def save_html(html, filename):\n",
    "    fhtml = open(filename, 'w')\n",
    "    fhtml.write(html)\n",
    "    fhtml.close()\n",
    "    \n",
    "def get_img_url(soup):\n",
    "    img_tag = soup.find(\"img\", id=\"imgSybj\")\n",
    "    if img_tag is None:\n",
    "        return None\n",
    "    else:\n",
    "        return img_tag.get(\"src\")\n",
    "    \n",
    "def get_zan_num(soup):\n",
    "    zan_num_tag = soup.find(\"span\", id=\"zan-num\")\n",
    "    if zan_num_tag is None:\n",
    "        return None\n",
    "    else:\n",
    "        return zan_num_tag.string\n",
    "    \n",
    "def get_cai_num(soup):\n",
    "    cai_num_tag = soup.find(\"span\", id=\"cai-num\")\n",
    "    if cai_num_tag is None:\n",
    "        return None\n",
    "    else:\n",
    "        return cai_num_tag.string\n",
    "    \n",
    "def get_prev_page(soup):\n",
    "    prev_page_tag = soup.find(\"a\", id=\"prepage\")\n",
    "    if prev_page_tag is None:\n",
    "        return None\n",
    "    else:\n",
    "        return prev_page_tag.get(\"href\")\n",
    "    \n",
    "def save_image(src_url, trg_name):\n",
    "    urllib.urlretrieve(src_url, trg_name)\n",
    "    \n",
    "def get_img_id(url):\n",
    "    _idx = url.find(\"&id=\") + 4\n",
    "    img_id = url[_idx:]\n",
    "    return img_id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    first_page = \"/may.php?c=w&a=organizationCommunity&t=1&hid=1126&id=405\"\n",
    "    href = first_page\n",
    "    #while href is not None:\n",
    "    for _ in range(10):\n",
    "        img_id = get_img_id(href)\n",
    "        if (not href.startswith(\"/may.php?\")) or (img_id == \"\"):\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            logging.info(\"process url=%s%s\"%(request_root_url, href))\n",
    "            \n",
    "            html = get_html(href)\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            save_html(html, \"./data/cache/%s.html\"%img_id)\n",
    "            logging.info(\"[html]./data/cache/%s.html has been saved.\"%img_id)\n",
    "                \n",
    "            img_url = get_img_url(soup)\n",
    "            zan_num = get_zan_num(soup)\n",
    "            cai_num = get_cai_num(soup)\n",
    "            img_filename = \"./data/img/%s_%s_%s.jpg\" % (img_id, zan_num, cai_num)\n",
    "            save_image(img_url, img_filename)\n",
    "            logging.info(\"[image]%s has been saved.\"%img_filename)\n",
    "        except Exception, e:\n",
    "            logging.error(e.message)\n",
    "            time.sleep(sleep_second*10)\n",
    "            continue\n",
    "        \n",
    "        href = get_prev_page(soup)\n",
    "        time.sleep(sleep_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Process, Semaphore, Lock, Queue, Pool\n",
    "import os\n",
    "\n",
    "path = \"./data/cache/\"\n",
    "\n",
    "img_tags_file = open(\"./data/img_tags.csv\", 'w')\n",
    "img_author_file = open(\"./data/img_author.csv\", 'w')\n",
    "\n",
    "img_tags_lock = Lock()\n",
    "img_author_lock = Lock()\n",
    "\n",
    "def Parser(html_file):\n",
    "    imgid = os.path.splitext(html_file)[0]\n",
    "    html_file = path + html_file\n",
    "    html = open(html_file, 'r').read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    author_div = soup.find(\"div\", class_=\"auther\")\n",
    "    tag_div = soup.find(\"div\", text=u\"标签\")\n",
    "    \n",
    "    if tag_div is not None:\n",
    "        try:\n",
    "            img_tags_lock.acquire()\n",
    "            tag = tag_div.parent.a.div.string.strip().encode(\"gbk\")\n",
    "            img_tags_file.write(\"%s\\t%s\\n\"%(imgid, tag))\n",
    "            img_tags_file.flush()\n",
    "        except:\n",
    "            pass\n",
    "        finally:\n",
    "            img_tags_lock.release()\n",
    "    \n",
    "    if author_div is not None:\n",
    "        try:\n",
    "            img_author_lock.acquire()\n",
    "            author = author_div.a.string.strip().encode(\"gbk\")\n",
    "            img_author_file.write(\"%s\\t%s\\n\"%(imgid, author))\n",
    "            img_author_file.flush()\n",
    "        except:\n",
    "            pass\n",
    "        finally:\n",
    "            img_author_lock.release()\n",
    "    \n",
    "p = Pool(processes=16)\n",
    "p.map(Parser, os.listdir(path))\n",
    "p.close()\n",
    "p.join()\n",
    "    \n",
    "img_tags_file.flush()\n",
    "img_author_file.flush()\n",
    "img_tags_file.close()\n",
    "img_author_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print soup.find(\"div\", text=u\"标签\").parent.a.div.string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print soup.find(\"div\", class_=\"auther\").a.string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
